#!/usr/bin/env python
# coding=UTF-8
"""
å¯ç›´æ¥è¿è¡Œçš„å¯¹æŠ—æ”»å‡»æ¼”ç¤ºè„šæœ¬
è‡ªåŠ¨å¤„ç†å¯¼å…¥é—®é¢˜ï¼Œå±•ç¤ºFGSMæ”»å‡»æ•ˆæœ
"""

import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

# ä¿®å¤ç›¸å¯¹å¯¼å…¥é—®é¢˜
import importlib.util

# åŠ¨æ€å¯¼å…¥attackæ¨¡å—
attack_path = os.path.join(current_dir, "attack.py")
if os.path.exists(attack_path):
    spec = importlib.util.spec_from_file_location("attack", attack_path)
    attack_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(attack_module)
    sys.modules['attack'] = attack_module

# åŠ¨æ€å¯¼å…¥fgsmæ¨¡å—
fgsm_path = os.path.join(current_dir, "fgsm.py")
if os.path.exists(fgsm_path):
    spec = importlib.util.spec_from_file_location("fgsm", fgsm_path)
    fgsm_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(fgsm_module)
    FGSM = fgsm_module.FGSM
else:
    print("é”™è¯¯: æ‰¾ä¸åˆ° fgsm.py æ–‡ä»¶")
    sys.exit(1)

import random
import torch
import torchvision
from torchvision.models import ResNet18_Weights
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ImageNetç±»åˆ«æ ‡ç­¾
IMAGENET_LABELS = []


def get_label_name(idx):
    """æ ¹æ®ç´¢å¼•è¿”å›ImageNetç±»åˆ«åç§°"""
    if 0 <= idx < len(IMAGENET_LABELS):
        return IMAGENET_LABELS[idx]
    return f"ç±»åˆ« {idx}"


def main():
    print("="*60)
    print("å¯¹æŠ—æ”»å‡»æ¼”ç¤º - FGSMæ–¹æ³•")
    print("="*60)
    
    # 1. è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    
    # 2. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    print("\næ­£åœ¨åŠ è½½ResNet18æ¨¡å‹...")
    try:
        weights = ResNet18_Weights.DEFAULT
        global IMAGENET_LABELS
        IMAGENET_LABELS = weights.meta.get("categories", [])
        model = torchvision.models.resnet18(weights=weights)
        model.eval().to(device)
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("æç¤º: è¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ï¼Œæˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æƒé‡")
        return
    
    # 3. å‡†å¤‡æµ‹è¯•å›¾åƒ
    print("\næ­£åœ¨å‡†å¤‡æµ‹è¯•å›¾åƒ...")
    
    # å°è¯•ä»imagesç›®å½•åŠ è½½å›¾ç‰‡
    images_dir = "images"
    test_image = None
    image_path = None
    
    if os.path.exists(images_dir):
        # è·å–imagesç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = [f for f in os.listdir(images_dir) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        
        if image_files:
            # éšæœºé€‰æ‹©ä¸€å¼ å›¾ç‰‡
            selected_file = random.choice(image_files)
            image_path = os.path.join(images_dir, selected_file)
            print(f"ä» {images_dir}/ ç›®å½•éšæœºåŠ è½½å›¾ç‰‡: {os.path.basename(image_path)}")
            
            try:
                transform = transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.ToTensor(),
                ])
                
                pil_image = Image.open(image_path).convert('RGB')
                test_image = transform(pil_image).unsqueeze(0)  # æ·»åŠ batchç»´åº¦
                print(f"âœ“ æˆåŠŸåŠ è½½å›¾ç‰‡")
            except Exception as e:
                print(f"âœ— åŠ è½½å›¾ç‰‡å¤±è´¥: {e}")
                print("  ä½¿ç”¨éšæœºå›¾ç‰‡ä½œä¸ºæ›¿ä»£")
                test_image = None
    
    # å¦‚æœæ²¡æœ‰æˆåŠŸåŠ è½½ï¼Œä½¿ç”¨éšæœºå›¾ç‰‡
    if test_image is None:
        print("ä½¿ç”¨éšæœºç”Ÿæˆçš„æµ‹è¯•å›¾ç‰‡")
        print("æç¤º: è¿è¡Œ 'python download_test_images.py' ä¸‹è½½æµ‹è¯•å›¾ç‰‡")
        test_image = torch.rand(1, 3, 224, 224)
    
    # è·å–åŸå§‹é¢„æµ‹
    with torch.no_grad():
        outputs = model(test_image.to(device))
        _, predicted = torch.max(outputs, 1)
        original_pred = predicted.item()
        original_conf = torch.softmax(outputs, dim=1)[0, original_pred].item()
    
    orig_label_name = get_label_name(original_pred)
    print(f"åŸå§‹å›¾åƒé¢„æµ‹: ç±»åˆ« {original_pred} ({orig_label_name}), ç½®ä¿¡åº¦: {original_conf:.4f}")
    
    # 4. åˆ›å»ºFGSMæ”»å‡»
    print("\næ­£åœ¨åˆ›å»ºFGSMæ”»å‡»å¯¹è±¡...")
    config = {
        "epsilon": 0.05  # æ‰°åŠ¨å¤§å°
    }
    
    try:
        attack = FGSM(
            model=model, 
            device=device, 
            IsTargeted=False,  # éç›®æ ‡æ”»å‡»
            config=config
        )
        print("âœ“ æ”»å‡»å¯¹è±¡åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âœ— æ”»å‡»å¯¹è±¡åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 5. ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
    print("\næ­£åœ¨ç”Ÿæˆå¯¹æŠ—æ ·æœ¬...")
    try:
        labels = torch.tensor([original_pred])
        adversarial_image = attack.generate(xs=test_image, ys=labels)
        print("âœ“ å¯¹æŠ—æ ·æœ¬ç”ŸæˆæˆåŠŸ")
    except Exception as e:
        print(f"âœ— å¯¹æŠ—æ ·æœ¬ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 6. æµ‹è¯•å¯¹æŠ—æ ·æœ¬
    with torch.no_grad():
        adv_outputs = model(adversarial_image.to(device))
        _, adv_predicted = torch.max(adv_outputs, 1)
        adv_pred = adv_predicted.item()
        adv_conf = torch.softmax(adv_outputs, dim=1)[0, adv_pred].item()
    
    adv_label_name = get_label_name(adv_pred)
    print(f"å¯¹æŠ—æ ·æœ¬é¢„æµ‹: ç±»åˆ« {adv_pred} ({adv_label_name}), ç½®ä¿¡åº¦: {adv_conf:.4f}")
    
    # 7. è®¡ç®—æ‰°åŠ¨
    perturbation = (adversarial_image - test_image).abs()
    max_pert = perturbation.max().item()
    mean_pert = perturbation.mean().item()
    
    print(f"\næ‰°åŠ¨ç»Ÿè®¡:")
    print(f"  æœ€å¤§æ‰°åŠ¨: {max_pert:.6f}")
    print(f"  å¹³å‡æ‰°åŠ¨: {mean_pert:.6f}")
    
    # 8. åˆ¤æ–­æ”»å‡»æ˜¯å¦æˆåŠŸ
    attack_success = original_pred != adv_pred
    if attack_success:
        print(f"\nğŸ‰ æ”»å‡»æˆåŠŸï¼æ¨¡å‹è¢«æ¬ºéª—äº†")
        print(f"   åŸå§‹é¢„æµ‹: ç±»åˆ« {original_pred} ({orig_label_name})")
        print(f"   å¯¹æŠ—é¢„æµ‹: ç±»åˆ« {adv_pred} ({adv_label_name})")
    else:
        print(f"\nâš ï¸  æ”»å‡»å¤±è´¥ï¼Œæ¨¡å‹ä»ç„¶æ­£ç¡®é¢„æµ‹")
        print(f"   æç¤º: å°è¯•å¢å¤§ epsilon å€¼ï¼ˆå½“å‰: {config['epsilon']}ï¼‰")
    
    # 9. å¯è§†åŒ–ç»“æœ
    print("\næ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾åƒ...")
    try:
        visualize_results(
            test_image, 
            adversarial_image, 
            original_pred, 
            adv_pred,
            orig_label_name,
            original_conf,
            adv_label_name,
            adv_conf,
            max_pert,
            attack_success
        )
        print("âœ“ å¯è§†åŒ–å®Œæˆï¼Œå›¾åƒå·²ä¿å­˜")
    except Exception as e:
        print(f"âœ— å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def visualize_results(original, adversarial, orig_pred, adv_pred, orig_label_name, orig_conf, adv_label_name, adv_conf, max_pert, success):
    """å¯è§†åŒ–æ”»å‡»ç»“æœ"""
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # è½¬æ¢ä¸ºnumpyæ ¼å¼
    orig_img = original[0].permute(1, 2, 0).cpu().numpy()
    orig_img = np.clip(orig_img, 0, 1)
    
    adv_img = adversarial[0].permute(1, 2, 0).cpu().numpy()
    adv_img = np.clip(adv_img, 0, 1)
    
    # è®¡ç®—æ‰°åŠ¨ï¼ˆæ”¾å¤§æ˜¾ç¤ºï¼‰
    pert = (adversarial - original)[0].abs()
    pert_img = pert.permute(1, 2, 0).cpu().numpy()
    pert_img = pert_img / pert_img.max() if pert_img.max() > 0 else pert_img
    
    # ç»˜åˆ¶åŸå§‹å›¾åƒ
    axes[0].imshow(orig_img)
    label_text = orig_label_name or get_label_name(orig_pred)
    axes[0].set_title(f'åŸå§‹å›¾åƒ\né¢„æµ‹: {orig_pred} - {label_text}\nç½®ä¿¡åº¦: {orig_conf:.3f}', 
                      fontsize=12, fontweight='bold')
    axes[0].axis('off')
    
    # ç»˜åˆ¶å¯¹æŠ—æ ·æœ¬
    color = 'red' if success else 'black'
    success_text = "âœ“ æ”»å‡»æˆåŠŸ" if success else "âœ— æ”»å‡»å¤±è´¥"
    axes[1].imshow(adv_img)
    adv_label_text = adv_label_name or get_label_name(adv_pred)
    axes[1].set_title(f'å¯¹æŠ—æ ·æœ¬ (FGSM)\né¢„æµ‹: {adv_pred} - {adv_label_text}\nç½®ä¿¡åº¦: {adv_conf:.3f}\n{success_text}', 
                     fontsize=12, fontweight='bold', color=color)
    axes[1].axis('off')
    
    # ç»˜åˆ¶æ‰°åŠ¨
    axes[2].imshow(pert_img, cmap='hot')
    axes[2].set_title(f'æ·»åŠ çš„æ‰°åŠ¨ (æ”¾å¤§æ˜¾ç¤º)\næœ€å¤§æ‰°åŠ¨: {max_pert:.6f}', 
                     fontsize=12, fontweight='bold')
    axes[2].axis('off')
    
    plt.suptitle('å¯¹æŠ—æ”»å‡»æ•ˆæœå¯¹æ¯” - FGSM', fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    output_file = 'attack_demo_result.png'
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"   ä¿å­˜ä½ç½®: {output_file}")
    
    # æ˜¾ç¤ºå›¾åƒ
    try:
        plt.show()
    except:
        print("   æ³¨æ„: æ— æ³•æ˜¾ç¤ºå›¾åƒï¼ˆå¯èƒ½åœ¨æ²¡æœ‰å›¾å½¢ç•Œé¢çš„ç¯å¢ƒä¸­ï¼‰")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nå‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        print("\næç¤º: è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–:")
        print("  pip install torch torchvision matplotlib numpy pillow")

